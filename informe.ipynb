{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1 - Aprendiz de damas chinas\n",
    "\n",
    "### Grupo 13:\n",
    "     - J. Aguirre  C.I: 4.773.509-6\n",
    "     - A. Collazo C.I: 4.455.617-4\n",
    "     - G. Núnez C.I: 4.785.081-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El principal objetivo de esta tarea es construir un jugador que aprenda a jugar a las damas chinas siguendo los lineamientos expuestos en el capítulo 1 del libro del curso.\n",
    "    \n",
    "El éxito del aprendizaje se medirá a través de la cantidad de partidas ganadas sobre un total de partidas jugadas previamente configurado.\n",
    "    \n",
    "El conjunto de entrenamiento será el resultado de las partidas jugadas ante dos tipos de adversarios: un jugador aleatorio, y un jugador que conforma una versión anterior del propio aprendiz.\n",
    "   \n",
    "Para valorar el aprendizaje se definirá una función objetivo cuyo resultado será un valor numérico que será más alto para aquellos tableros que sean más promisorios. Dicha función estará implementada a partir de una representación del tablero convenientemente elegida, a los efectos de aprender a jugar y conseguir mayor porcentaje de victorias a través de la experiencia.\n",
    "\n",
    "En el presente informe se describirá la solución implementada, los resultados intermedios obtenidos y se explicará el por qué de los mismos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente sección se mencionan las decisiones de diseño utilizadas en los distintos aspectos del juego, la representación lógica del tablero, los algoritmos utilizados para la implementación del aprendiz y la construcción de los jugadores oponentes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation*}\n",
       "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
       "               1              & t_1 = 10\\\\\n",
       "               -1               & t_2 = 10\\\\\n",
       "               \\sum t_i * w_i & \\text{sino}\n",
       "           \\end{cases}\n",
       "\\end{equation*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{equation*}\n",
    "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
    "               1              & t_1 = 10\\\\\n",
    "               -1               & t_2 = 10\\\\\n",
    "               \\sum t_i * w_i & \\text{sino}\n",
    "           \\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 2.1 Juego\n",
    "### 2.1.1 Reglas\n",
    "Las reglas utilizadas para el juego son las mismas que se aplican en el juego de las damas chinas convencional a excepción de las siguientes simplificaciones:\n",
    "* Dado que las partidas son siempre de dos jugadores el tablero fue simplificado, omitiendo cuatro de las seis puntas de la estrella. Por lo tanto el tablero resultante está formado por un hexágono de nueve casilleros de largo, y dos triángulos opuestos, de largo cuatro casilleros cada uno.\n",
    "* Una vez que una ficha alcanza su triángulo objetivo, la misma no podrá realizar movimientos hacia atrás en el tablero. Esta decisión fue tomada para que el jugador randómico no saque fichas de las posiciones ganadoras.\n",
    "* Se limita a poder realizar un único salto por jugada, ya que no se consideró como una casuística a suceder a menudo.\n",
    "* Se define un número máximo de jugadas realizadas por ambos jugadores durante todo el partido. En caso de que el jugador aprendiz no sea capaz de vencer a su oponente en menos de diez mil jugadas, el partido será computado como perdido para el jugador aprendiz si éste tiene menos de 5 fichas en posición ganadoras. De lo contrario será computado como ganador para el jugador aprendiz.\n",
    "* En el caso de atascamiento (situación que se da cuando un jugador tiene fichas en el triángulo ganador y su contrincante aún no saco las fichas que están en el nivel superior de su triángulo), se desechará la partida del conjunto de aprendizaje.\n",
    "\n",
    "## 2.2 Tablero\n",
    "Con el objetivo de contabilizar el grado de avance de las fichas (de cada jugador), el tablero fue particionado en cinco regiones lógicas: las fichas en posición inicial, en posición lejana del triángulo objetivo, las que están a mitad de camino, las cercanas al triángulo objetivo y finalmente las fichas en posición ganadora. Todas las regiones son de largo tres casilleros a excepción de la primer y última región que tienen largo cuatro cada una.\n",
    "A partir de esto, se define la representación del tablero como una tupla de diez valores, donde cada valor representa la cantidad de fichas de cada jugador en: (región inicial, región lejana, región media, región cercana, región ganadora).\n",
    "\n",
    "En las figuras 2.1 y 2.2 se muestran dos ejemplos de posibles tableros con sus respectivas tuplas que los representan. (PONER IMAGENES DE TABLEROS CON FICHAS EN DISTINTAS POSICIONES Y LA TUPLA CORRESPONDIENTE A ESA SITUACION) \n",
    "\n",
    "\n",
    "\n",
    "## 2.3 Algoritmo\n",
    "La función de valoración es una función partida en tres rangos:\n",
    "\\begin{equation*}\n",
    "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
    "               1              & t_1 = 10\\\\\n",
    "               -1               & t_2 = 10\\\\\n",
    "               \\sum t_i * w_i & \\text{sino}\n",
    "           \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Cada una de las variables está multiplicada por una ponderación que representa la relevancia del valor del atributo en la estrategia de juego.\n",
    "El dominio de la función de valoración está definida en todos los reales entre -1 y 1.\n",
    "\n",
    "Los función se ajusta siguiendo el algoritmo LMS al término de una cantidad de partidas dada. Dicha cantidad de partidos es configurable al inicio del entrenamiento. El vector de pesos obtenido es normalizdo de manera tal que el valor de cada uno de ellos se mantiene en el rango entre -1 y 1.\n",
    "En la sección 3.1 se tabulan los resultados obtenidos ajustando la función de valoración cada 1, 10, 100 y 1.000 partidos jugados.\n",
    "\n",
    "El ajuste de los pesos está afectado por una factor de aprendizaje ($\\mu$).\n",
    "Dicho factor de aprendizaje se ajusta según el resultado del partido, de la forma que sigue: \\begin{equation*}\n",
    "    f(win) = \\begin{cases}\n",
    "               0.0000001              & win = 1\\\\\n",
    "               0.0001               & \\text{sino}\n",
    "             \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "En caso de obtener una partida ganadora, el ajuste del aprendizaje se enfriará, ya que está cumpliendo el objetivo.\n",
    "\n",
    "## 2.4 Contrarios\n",
    "Se definen dos tipos de jugadores oponentes:\n",
    "* Un jugador que elige sus movimientos al azar\n",
    "* Un jugador que constituye una versión previa del jugador aprendiz actual.\n",
    "\n",
    "### 2.4.1 Jugador azaroso\n",
    "Las jugadas se eligen de forma aleatoria sobre un subconjunto de jugadas válidas para cierta ficha (elegida también de forma aleatoria). Como se mencionó anteriormente, una vez que una ficha alcanza la región ganadora se limita a que únicamente avance (en caso de ser posible) para llenar el triángulo del adversario e impedir que retire las fichas de dicha región.\n",
    "En caso de que no haya movimiento disponible para la ficha elegida, se selecciona otra elegida nuevamente al azar (notar que eventualmente podría llegar a ser la misma).\n",
    "\n",
    "### 2.4.2 Versión previa del aprendiz actual\n",
    "En esta instancia el contrincante utiliza como pesos iniciales a los penultimos pesos configurados por el aprendiz, mientras que el mismo utilizará los pesos que obtuvo al terminar la última partida de entrenamiento ante el oponente aleatorio. Luego tanto el jugador aprendiz (algoritmo LMS) como su contrincante (vector anterior), actualizan los pesos conforme al parámetro de ajuste mencionado anteriormente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterios de entrenamiento:\n",
    "\n",
    "En los casos de prueba con pocos partidos jugados los resultados \n",
    "\n",
    "### 3.1 Fase de entrenamiento vs. el jugador azaroso\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>10</td>\n",
    "    <td>364</td>\n",
    "    <td>0</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>50</td>\n",
    "    <td>405</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>100</td>\n",
    "    <td>403</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>1.000</td>\n",
    "    <td>250</td>\n",
    "    <td>413</td>\n",
    "    <td>0</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 1.1 - Entrenamiento del aprendiz ante el jugador aleatorio partiendo siempe desde los mismos pesos iniciales, variando la frecuencia de ajuste para una cantidad total de partidos fija.</caption>\n",
    "</table>\n",
    "\n",
    "Para este caso de prueba, los mejores resultados ocurrieron en el último caso, cuando transcurre mayor cantidad de partidos jugados antes de actualizar los pesos. \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>\n",
    "    <th>Porcentaje de partidos ganados</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>1</td>\n",
    "    <td>4</td>\n",
    "    <td>0</td>\n",
    "    <td>40%</td>  \n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>10</td>\n",
    "    <td>39</td>\n",
    "    <td>0</td>\n",
    "    <td>39%</td>  \n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>1.000</td>\n",
    "    <td>100</td>\n",
    "    <td>403</td>\n",
    "    <td>0</td>\n",
    "    <td>40.3%</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10.000</td>\n",
    "    <td>1000</td>\n",
    "    <td>3.862</td>\n",
    "    <td>0</td>\n",
    "    <td>38.62%</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100.000</td>\n",
    "    <td>10.000</td>\n",
    "    <td>38.616</td>\n",
    "    <td>0</td>\n",
    "    <td>38.61%</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 1.2 - Entrenamiento del aprendiz ante el jugador aleatorio partiendo siempe desde los mismos pesos iniciales.</caption>\n",
    "</table>\n",
    "\n",
    "Aquí se puede ver que la cantidad de partidos ganados no tiene grandes variaciones a medida que se aumenta la cantidad de partidos jugados. Notar que la frecuencia de ajuste de los pesos se mantiene proporcional en todos los casos.\n",
    "\n",
    "En conclusión, a partir de los resultados obtenidos puede detectarse que no hay una mejora a traves de la experiencia, es decir que una mayor cantidad de partidas jugadas no refleja una mayor cantidad de partidas ganadas(proporcionalmente). Por lo tanto hay errores inherentes al modelo, o no se cumple alguna hipotesis (puntos que se desarrollan en la sección 4).\n",
    "\n",
    "\n",
    "### 3.2 Fase de entrenamiento vs. la versión previa del aprendiz actual\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>  \n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>1</td>\n",
    "    <td>47</td>\n",
    "    <td>27</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>2</td>\n",
    "    <td>32</td>\n",
    "    <td>34</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>10</td>\n",
    "    <td>37</td>\n",
    "    <td>25</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>25</td>\n",
    "    <td>28</td>\n",
    "    <td>37</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 2.1 - Entrenamiento del aprendiz ante la versión previa partiendo desde los pesos iniciales obtenidos en el mejor resultado del entrenamiento anterior, variando la frecuencia de ajuste para una cantidad total de partidos fija.</caption>\n",
    "</table>\n",
    "\n",
    "En este caso, los mejores resultados se obtienen cuando los jugadores ajustan sus pesos al final de cada partido. En comparación con el mismo experimento realizado con el jugador aleatorio, la proporción de la frecuencia de ajuste es la misma. La diferencia está en la cantidad total de partidos jugados. Para este caso se redujo el total de partidos ya que para una cantidad mayor a 100 los jugadores se estancan.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>\n",
    "    <th>Porcentaje de partidos ganados</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>1</td>\n",
    "    <td>4</td>\n",
    "    <td>3</td>\n",
    "    <td>40%</td>  \n",
    "  </tr>    \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>10</td>\n",
    "    <td>37</td>\n",
    "    <td>25</td>\n",
    "    <td>37%</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>100</td>\n",
    "    <td>35</td>\n",
    "    <td>32</td>\n",
    "    <td>-</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10.000</td>\n",
    "    <td>1000</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100.000</td>\n",
    "    <td>10.000</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 2.2 - Entrenamiento del aprendiz ante la versión partiendo desde los pesos iniciales obtenidos en el mejor resultado del entrenamiento anterior.</caption>\n",
    "</table>\n",
    "\n",
    "HABLAR DE QUE SE EMPIEZA A TRANCAR LUEGO DE LOS 100 PARTIDOS. \n",
    "AGREGAR QUE SE PROBÓ CON OTROS PESOS INICIALES Y QUE EL RESULTADO MEJORA UN POCO PERO DESPUÉS DE 500 PARTIDOS SE VUELVE A TRANCAR. EXPLICAR POR QUE PASA ESTO (AJUSTA LOS PESOS BIEN AL PRINCIPIO PERO LUEGO DESAPRENDE).\n",
    "\n",
    "### 3.3 Competencia entre los jugadores obtenidos durante las fases de entrenamiento\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Ganados por jugador entrenado vs. aleatorio</th>\n",
    "    <th>Ganados por jugador entrenado vs. versión previa</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>34</td>\n",
    "    <td>38</td> \n",
    "  </tr>    \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>33</td>\n",
    "    <td>38</td> \n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>35</td>\n",
    "    <td>31</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>33</td>\n",
    "    <td>33</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>33</td>\n",
    "    <td>32</td> \n",
    "  </tr>  \n",
    "    <caption>Tabla 3.1 - Resultados de la competencia entre los jugadores obtenidos con cada entrenamiento .</caption>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21c2cca780>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot.plot(range(0,100), [2**-(x/10) for x in range(0,100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Debe existir alguna instancia donde se compile la información relevante de los experimentos de forma de poder comparar fácilmente los distintos experimentos. Por ejemplo:\n",
    "\n",
    "_En la tabla 1, se presentan los distintos resultados contra el jugador aleatorio, para los distintos valores de $\\alpha$ elegidos. El mejor resultado se obtiene para $\\alpha=0.05$, lo que prueba que la estrategia..._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
    "\n",
    "Culminadas las etapas del desarrollo del modelo y experimentación, puede concluirse que no se logró el objetivo de implementar un aprendiz 'competente', dado que no pudo canalizarse el aprendizaje a traves de la experiencia.\n",
    "\n",
    "En el desarrollo del modelo, las elecciones con respecto al tablero tienen las siguientes limitantes:\n",
    "\n",
    "\n",
    "Durante la fase de entrenamiento frente al jugador aleatorio, los resultados en general son buenos, dado que en todos los casos de prueba el jugador logra el cometido de incrementar la cantidad de partidos ganados a raíz de su experiencia.\n",
    "\n",
    "Los resultados obtenidos frente a la verión previa los resultados no son los esperados. Aquí se ve que el aprendizaje se frena bastante. Esto se debe a limitaciones asociadas al modelo propuesto e hipotesis que no se cumplen:\n",
    "* Dividir el tablero en segmentos de cercanía no fue provechoso, ya que se incurre en situaciones en las que al no cambiar de conjunto no hay retibución al avance, por lo que la ponderacion de adelantar o atrasar una ficha (dentro del mismo rango) es igual.\n",
    "* La tupla elegida para representar el tablero contiene información relativa al jugador contrario, pero no se toman acciones que limiten su juego como el bloquearlo (AUNQUE SE HIZO UNA PRUEBA DE CONCEPTO, ACERCA DE GUARDAR SOLAMENTE INFORMACION DE P1, PERO SIN RESULTADO FAVORABLE. \n",
    "* El aprendizaje inicial comienza su entrenamiento frente a un jugador aleatorio, por lo que la hipótesis de que en todo momento realizará el mejor movimiento posible no es válida, lo que puede llevar a condicionar la forma de jugar del jugador aprendiz. \n",
    "\n",
    "Sin embargo, futuras mejorías pueden guiar hacia mejores resultados:\n",
    "* Computar n jugadas siguientes de la instancia actual, de manera de evaluar un mayor conjunto de posibilidades (propias y del rival) asumiendo el costo computacional que conlleva.\n",
    "* Cambiar las regiones de distancia por la distancia propiamente dicha.\n",
    "* Considerar la posibilidad de bloquear las fichas del oponente.\n",
    "* Favorecer la estrategia de ataque utilizando saltos de largo mayor que 1.\n",
    "* Cambiar el contrincante puramente aleatorio, por uno con un criterio estatico de decisión, que genere mejores datos de entrada, es decir que compita frente a una estrategia (macro) como puede ser: intentar avanzar siempre, intentar generar bloqueos, otras.\n",
    "\n",
    "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
