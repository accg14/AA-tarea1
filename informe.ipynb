{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1 - Aprendiz de damas chinas\n",
    "\n",
    "### Grupo 13:\n",
    "     - J. Aguirre  C.I: 4.773.509-6\n",
    "     - A. Collazo C.I: 4.455.617-4\n",
    "     - G. Núnez C.I: 4.785.081-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El principal objetivo de esta tarea es construir un jugador que aprenda a jugar a las damas chinas siguendo los lineamientos expuestos en el capítulo 1 del libro del curso.\n",
    "    \n",
    "El éxito del aprendizaje se medirá a través de la cantidad de partidas ganadas sobre un total de partidas jugadas previamente configurado.\n",
    "    \n",
    "El conjunto de entrenamiento será el resultado de las partidas jugadas ante dos tipos de adversarios: un jugador aleatorio, y un jugador que conforma una versión anterior del propio aprendiz.\n",
    "   \n",
    "Para valorar el aprendizaje se definirá una función objetivo cuyo resultado será un valor numérico que será más alto para aquellos tableros que sean más promisorios. Dicha función estará implementada a partir de una representación del tablero convenientemente elegida, a los efectos de aprender a jugar y conseguir mayor porcentaje de victorias a través de la experiencia.\n",
    "\n",
    "En el presente informe se describirá la solución obtenida, los resultados intermedios obtenidos y se explicará el por qué de los mismos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente sección se mencionan las decisiones de diseño utilizadas en los distintos aspectos del juego, la representación lógica del tablero, los algoritmos utilizados para la implementación del aprendiz y la construcción de los jugadores oponentes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation*}\n",
       "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
       "               1              & t_1 = 10\\\\\n",
       "               -1               & t_2 = 10\\\\\n",
       "               \\sum t_i * w_i & \\text{sino}\n",
       "           \\end{cases}\n",
       "\\end{equation*}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{equation*}\n",
    "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
    "               1              & t_1 = 10\\\\\n",
    "               -1               & t_2 = 10\\\\\n",
    "               \\sum t_i * w_i & \\text{sino}\n",
    "           \\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.1 Juego\n",
    "### 2.1.1 Reglas\n",
    "Las reglas utilizadas para el juego son las mismas que se aplican en el juego de las damas chinas convencional a excepción de las siguientes simplificaciones:\n",
    "* Dado que las partidas son siempre de dos jugadores el tablero fue simplificado, omitiendo cuatro de las seis puntas de la estrella. Por lo tanto el tablero resultante está formado por un hexágono de nueve casilleros de largo, y dos triángulos opuestos, de largo cuatro casilleros cada uno.\n",
    "* Una vez que una ficha alcanza su triángulo objetivo, la misma no podrá realizar movimientos hacia atrás en el tablero. Esta decisión fue tomada para que el jugador randómico no saque fichas de las posiciones ganadoras.\n",
    "* Se limita a poder realizar un único salto por jugada, ya que no se considero como una casuistica a suceder a menudo. (AGREGAR LA JUSTIFICACION)\n",
    "* Se define un número máximo de jugadas realizadas por ambos jugadores durante todo el partido. En caso de que el jugador aprendiz no sea capaz de vencer a su oponente en menos de X_(PONER CUANTAS) jugadas, el partido será computado como perdido para el jugador aprendiz.\n",
    "* En el caso de atascamiento (EXPLICAR UN PCO MAS ESOT), se desechara la partida del conjunto de aprendizaje.\n",
    "\n",
    "## 2.2 Tablero\n",
    "Con el objetivo de contabilizar el grado de avance de las fichas (de cada jugador), el tablero fue particionado en cinco regiones lógicas: las fichas en posición inicial, en posición lejana del triángulo objetivo, las que están a mitad de camino, las cercanas al triángulo objetivo y finalmente las fichas en posición ganadora. Todas las regiones son de largo tres casilleros a excepción de la primer y última región que tienen largo cuatro cada una.\n",
    "A partir de esto, se define la representación del tablero como una tupla de diez valores, donde cada valor representa la cantidad de fichas de cada jugador en: (región inicial, región lejana, región media, región cercana, región ganadora).\n",
    "\n",
    "En las figuras 2.1 y 2.2 se muestran dos ejemplos de posibles tableros con sus respectivas tuplas que los representan. (PONER IMAGENES DE TABLEROS CON FICHAS EN DISTINTAS POSICIONES Y LA TUPLA CORRESPONDIENTE A ESA SITUACION) \n",
    "\n",
    "\n",
    "\n",
    "## 2.3 Algoritmo\n",
    "La función de valoración es una función partida en tres rangos:\n",
    "\\begin{equation*}\n",
    "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
    "               1              & t_1 = 10\\\\\n",
    "               -1               & t_2 = 10\\\\\n",
    "               \\sum t_i * w_i & \\text{sino}\n",
    "           \\end{cases}\n",
    "\\end{equation*}\n",
    "Cada una de las variables está multiplicada por una ponderación que representa la relevancia del valor del atributo en la estrategia de juego.\n",
    "El dominio de la funcion de valoración está definida en todos los reales entre -1 y 1 (VER ESTO PORQUE NO ES LO QUE SE ESTÁ DEVOLVIENDO).\n",
    "\n",
    "Los función se ajusta siguiendo el algoritmo LMS al término de una cantidad de partidas dada. Dicha cantidad de partidos es configurable en el sentido de que se debe ingresar un parámetro que indique cada cuantos partidos se deben ajustar los pesos. El vector de pesos obtenido es normalizdo por su norma de manera tal que el valor de cada uno de ellos se mantiene en el rango entre -1 y 1.\n",
    "En la sección tal.tanto se tabulan los resultados obtenidos ajustando la función de valoración cada w, x e y partidos jugados.\n",
    "\n",
    "El ajuste de los pesos está afectado por una factor de aprendizaje ($\\mu$).\n",
    "Dicho factor de aprendizaje se ajusta según el error relativo incurrido en una muestra de entrenamiento (error de una partida, o promedio de error de n partidas del conjunto). En la tabla 2.1 se visualizan algunos de los valores de $\\mu$ obtenidos.\n",
    "\n",
    "- ¿Se utiliza enfriamiento? ¿cómo? (VER ESTE PUNTO)\n",
    "El factor de aprendizaje está categorizada en tres: 'bueno', 'regular', 'malo'. Dependiendo del error relativo cometido, se define el grado de ajuste del parámetro: 0,03, 0,06 y 0,09 respectivamente.\n",
    "\n",
    "\n",
    "Tal vez precisen agregar algo de pseudocódigo o código para ejemplificar:\n",
    "\n",
    "```python\n",
    "    def f(x):\n",
    "        return x\n",
    "```\n",
    "\n",
    "## 2.4 Contrarios\n",
    "Se definen dos tipos de jugadores oponentes:\n",
    "* Un jugador que elige sus movimientos al azar\n",
    "* Un jugador que constituye una versión previa del jugador aprendiz actual.\n",
    "\n",
    "### 2.4.1 Jugador azaroso\n",
    "Las jugadas se eligen de forma aleatoria sobre un subconjunto de jugadas válidas para cierta ficha (elegida también de forma aleatoria). Como se mencionó anteriormente, una vez que una ficha alcanza la región ganadora se limita a que únicamente avance (en caso de ser posible) para llenar el triángulo del adversario e impedir que retire las fichas de dicha región.\n",
    "En caso de que no haya movimiento disponible para la ficha elegida, se selecciona otra elegida nuevamente al azar (notar que eventualmente podría llegar a ser la misma).\n",
    "\n",
    "### 2.4.2 Versión previa del aprendiz actual\n",
    "En primera instancia este jugador utiliza los pesos iniciales que tenía nuestro aprendiz ante su adversario azaroso, y el jugador aprendiz utilizará los pesos que obtuvo al terminar la última partida de entrenamiento ante el oponente aleatorio. Luego el jugador aprendiz actualiza los pesos conforme al parámetro ingresado que marca la cantidad de partidos que deben transcurrir para que este vuelva a ajustar los pesos. Una vez que el jugador aprendiz actualiza los nuevos pesos, la versión previa configurará como sus pesos actuales, los pesos que tenía el aprendiz hasta antes de actualizarlos por los nuevos.\n",
    "(NO SE SI ESTO ES REALMENTE ASI, LO PUSE PARA REDACTAR ALGO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan los resultados obtenidos durante el proceso de aprendizaje.\n",
    "- Presentar los distintos experimentos que se realizan y los resultados que se obtienen.\n",
    "\n",
    "- La información de los resultados se presenta en tablas y en gráficos, de acuerdo a su naturaleza. Por ejemplo:\n",
    "\n",
    "_En la gráfica 1, se observa el error cuadrático total del conjunto de entrenamiento a medida que pasan los juegos para el oponente X_\n",
    "\n",
    "## 3.1 Fase de entrenamiento vs el jugador azaroso\n",
    "\n",
    "## 3.2 Fase de entrenamiento vs la versión previa del aprendiz actual\n",
    "\n",
    "## 3.3 Competencia entre los jugadores obtenidos durante las fases de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0b40cfa990>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot.plot(range(0,100), [2**-(x/10) for x in range(0,100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Debe existir alguna instancia donde se compile la información relevante de los experimentos de forma de poder comparar fácilmente los distintos experimentos. Por ejemplo:\n",
    "\n",
    "_En la tabla 1, se presentan los distintos resultados contra el jugador aleatorio, para los distintos valores de $\\alpha$ elegidos. El mejor resultado se obtiene para $\\alpha=0.05$, lo que prueba que la estrategia..._\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>$\\mu$</th>\n",
    "    <th>...</th>\n",
    "    <th>Turnos</th>\n",
    "    <th>Error</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.001</td>\n",
    "    <td>...</td>\n",
    "    <td>100</td>\n",
    "    <td>0.991</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>0.005</td>\n",
    "    <td>...</td>\n",
    "    <td>100</td>\n",
    "    <td>0.987</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>0.05</td>\n",
    "    <td>...</td>\n",
    "    <td>100</td>\n",
    "    <td>0.329</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.5</td>\n",
    "    <td>...</td>\n",
    "    <td>100</td>\n",
    "    <td>0.564</td>\n",
    "  </tr>    \n",
    "    <caption>Tabla 1 - Entrenamiento del jugador X para distintos valores de $\\alpha$</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
    "- ¿cuándo se dieron los mejores resultados del jugador?\n",
    "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
    "- ¿cómo mejoraría los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
