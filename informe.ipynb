{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1 - Aprendiz de damas chinas\n",
    "\n",
    "### Grupo 13:\n",
    "     - J. Aguirre  C.I: 4.773.509-6\n",
    "     - A. Collazo C.I: 4.455.617-4\n",
    "     - G. Núnez C.I: 4.785.081-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El principal objetivo de esta tarea es construir un jugador que aprenda a jugar a las damas chinas siguiendo los lineamientos expuestos en el capítulo 1 del libro del curso.\n",
    "El éxito del aprendizaje se medirá a través de la cantidad de partidas ganadas sobre el total de partidas jugadas (previamente determinado).\n",
    "\n",
    "El conjunto de entrenamiento será el resultado de las partidas jugadas contra dos tipos de adversarios: un jugador aleatorio, y un jugador que conforma una versión anterior del propio aprendiz.\n",
    "\n",
    "Para valorar el aprendizaje se definirá una función objetivo cuyo resultado será un valor numérico, siendo este más alto para aquellos tableros que sean promisorios de ganar. Dicha función estará implementada a partir de una representación del tablero convenientemente elegida, a los efectos de aprender a jugar y conseguir mayor porcentaje de victorias a través de la experiencia.\n",
    "\n",
    "En el presente informe se describe la solución implementada, los resultados intermedios obtenidos y se explica el porqué de estos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente sección se mencionan las decisiones de diseño utilizadas en los distintos aspectos del juego, la representación lógica del tablero, los algoritmos utilizados para la implementación del aprendiz y la construcción de los jugadores oponentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation*}\n",
       "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
       "               1              & t_1 = 10\\\\\n",
       "               -1               & t_2 = 10\\\\\n",
       "               \\sum t_i * w_i & \\text{sino}\n",
       "           \\end{cases}\n",
       "\\end{equation*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{equation*}\n",
    "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
    "               1              & t_1 = 10\\\\\n",
    "               -1               & t_2 = 10\\\\\n",
    "               \\sum t_i * w_i & \\text{sino}\n",
    "           \\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Juego\n",
    "### 2.1.1 Reglas\n",
    "Las reglas utilizadas para el juego son las mismas que se aplican para las damas chinas convencional a excepción de las siguientes simplificaciones:\n",
    "* Dado que las partidas son siempre entre dos jugadores, el tablero fue simplificado omitiendo cuatro de las seis puntas de la estrella. Por lo tanto, el tablero resultante consiste en un hexágono de nueve casilleros de largo, y dos triángulos opuestos de cuatro casilleros de largo cada uno.\n",
    "* Cuando una ficha es posicionada en el triángulo objetivo, la misma no puede ser movida hacia atrás en el tablero. Esta decisión fue tomada para que el jugador aleatorio no saque fichas de la zona objetivo.\n",
    "* Se limita a poder realizar un único salto por jugada, dado que poder realizar múltiples saltos en la misma jugada no se considera una casuística a suceder a menudo.\n",
    "* Se define un número máximo de diez mil jugadas que ambos jugadores pueden realizar durante el transcurso de la partida. En caso de que el jugador aprendiz no sea capaz de vencer a su oponente antes del límite de jugadas, será computado como perdido para el jugador aprendiz a no ser que tenga más de cinco fichas en posición ganadoras y, además, más fichas en posición ganadora que su oponente.\n",
    "* En caso de atascamiento (al menos una ficha del jugador aprendiz queda atrapada por fichas de su oponente en su propio triángulo, o viceversa, consecuencia de la segunda simplificación), se desecha la partida del conjunto de aprendizaje.\n",
    "\n",
    "\n",
    "## 2.2 Tablero\n",
    "Con el objetivo de contabilizar el grado de avance de las fichas de cada jugador, el tablero fue particionado en cinco regiones lógicas: las fichas en posición inicial, las fichas lejanas al triángulo objetivo, las fichas a mitad de camino, las fichas cercanas al triángulo objetivo y finalmente las fichas en posición ganadora. La primera y última región (correspondiente a las zonas objetivos), tienen un largo de cuatro casilleros cada una, mientras que las restantes tienen un largo de tres casilleros cada una. A partir de esto, se define la representación del tablero como una tupla de diez valores de la siguiente manera.\n",
    "\n",
    "<t0, ... , t9>\n",
    "\n",
    "t0, t1 = cantidad de fichas en posición ganadora del jugador aprendiz y del oponente, respectivamente\n",
    "\n",
    "t2, t3 = cantidad de fichas cercanas al triángulo objetivo del jugador aprendiz y del oponente, respectivamente.\n",
    "\n",
    "t4, t5 = cantidad de fichas a mitad de camino del jugador aprendiz y del oponente, respectivamente.\n",
    "\n",
    "t6, t7 = cantidad de fichas lejanas al triángulo objetivo del jugador aprendiz y del oponente, respectivamente.\n",
    "\n",
    "t8, t9 = cantidad de fichas en posición inicial del jugador aprendiz y del oponente, respectivamente.\n",
    "\n",
    "A continuación, se visualizan dos ejemplos de tableros con su correspondiente tupla.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "      <td><img src=\"Board1.png\" alt=\"Drawing\" style=\"width: 400px;\"/></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Figura 1: El tablero de la figura corresponde a la tupla [2, 0, 1, 2, 3, 3, 1, 4, 3, 1].</td>     \n",
    "    </tr>\n",
    "    <tr>\n",
    "     <td><img src=\"Board2.png\" alt=\"Drawing\" style=\"width: 400px;\"/></td>   \n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td>Figura 2: El tablero de la figura corresponde a la tupla [2, 3, 1, 0, 5, 2, 2, 3, 0, 2].</td>\n",
    "    </tr>    \n",
    "</table>\n",
    "\n",
    "\n",
    "## 2.3 Algoritmo\n",
    "La función de valoración es una función partida en tres rangos:\n",
    "\\begin{equation*}\n",
    "    f(<t_0,t_1,...,t_{10}>) = \\begin{cases}\n",
    "               1              & t_1 = 10\\\\\n",
    "               -1               & t_2 = 10\\\\\n",
    "               \\sum t_i * w_i & \\text{sino}\n",
    "           \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Cada una de las variables está multiplicada por una ponderación que representa la relevancia del valor del atributo en la estrategia de juego. El dominio de la función de valoración está definida en todos los reales entre -1 y 1. Notar que la función recibe una tupla de once parámetros, dado que incluye el término independiente.\n",
    "\n",
    "La función se ajusta siguiendo el algoritmo LMS al término de una cantidad de partidas dada. Dicha cantidad de partidas es configurable al inicio del entrenamiento. El vector de pesos obtenido es normalizado de manera tal que el valor de cada uno de ellos se mantiene en el rango [-1, 1]. \n",
    "\n",
    "En la sección 3.1 se tabulan los resultados obtenidos ajustando la función de valoración cada 1, 10, 100 y 1.000 partidas jugadas.\n",
    "El ajuste de los pesos está afectado por una factor de aprendizaje ($\\mu$). Como se muestra a continuación, dicho factor de aprendizaje se ajusta según el resultado de la partida.\n",
    "\n",
    " \\begin{equation*}\n",
    "    f(win) = \\begin{cases}\n",
    "               0.0000001              & win = 1\\\\\n",
    "               0.0001               & \\text{sino}\n",
    "             \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "En caso de obtener una partida ganadora, el ajuste del aprendizaje se enfriará, ya que está cumpliendo el objetivo.\n",
    "\n",
    "```python\n",
    "    def actualizar_pesos():\n",
    "        ajustar mu\n",
    "        algoritmo LMS\n",
    "```\n",
    "\n",
    "## 2.4 Contrarios\n",
    "Se definen dos tipos de jugadores oponentes:\n",
    "* Un jugador que elige sus movimientos al azar\n",
    "* Un jugador que constituye una versión previa del jugador aprendiz actual.\n",
    "\n",
    "### 2.4.1 Jugador azaroso\n",
    "Las jugadas se eligen de forma aleatoria sobre un subconjunto de jugadas válidas para cierta ficha (elegida también de forma aleatoria). Como se mencionó anteriormente, con el fin de impedir que el jugador retire las fichas de la región ganadora una vez que las posiciona, se limita la cantidad de movimientos para que únicamente avance (en caso de ser posible) o se mueva para los costado. En caso de que la ficha seleccionada no tenga algún movimiento disponible, se selecciona otra nuevamente al azar (notar que eventualmente podría llegar a ser la misma).\n",
    "\n",
    "\n",
    "### 2.4.2 Versión previa del aprendiz actual\n",
    "En esta instancia el contrincante utiliza los penúltimos pesos configurados por el aprendiz como pesos iniciales, mientras que el mismo utilizará los pesos que obtuvo al terminar la última partida de entrenamiento ante el oponente aleatorio. Luego tanto el jugador aprendiz (algoritmo LMS) como su contrincante (vector anterior), actualizan los pesos conforme al parámetro de ajuste mencionado anteriormente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los casos de prueba realizados durante ambos entrenamientos constan de dos partes.\n",
    "* La primera en donde se fija el total de partidos a disputar y se varía la frecuencia de ajuste de los pesos, con el objetivo de visualizar qué frecuencia permite obtener mayores resultados positivos.\n",
    "* La segunda donde se incrementa la cantidad de partidos y la frecuencia de ajuste de manera proporcional, con el objetivo de visualizar si la cantidad de partidos ganados crece de acuerdo al aumento de la experiencia.\n",
    "\n",
    "\n",
    "### 3.1 Fase de entrenamiento vs. el jugador azaroso\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>10</td>\n",
    "    <td>364</td>\n",
    "    <td>0</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>50</td>\n",
    "    <td>405</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>100</td>\n",
    "    <td>403</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>1.000</td>\n",
    "    <td>250</td>\n",
    "    <td>413</td>\n",
    "    <td>0</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 1 - Entrenamiento del aprendiz ante el jugador aleatorio partiendo siempe desde los mismos pesos iniciales, variando la frecuencia de ajuste para una cantidad total de partidos fija.</caption>\n",
    "</table>\n",
    "\n",
    "Se puede apreciar en Tabla 1, que el mejor resultado ocurre cuando se reduce la frecuencia de ajuste, es decir, a mayor cantidad de partidas jugadas sin ajustar los pesos. \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>\n",
    "    <th>Porcentaje de partidos ganados</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>1</td>\n",
    "    <td>4</td>\n",
    "    <td>0</td>\n",
    "    <td>40%</td>  \n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>10</td>\n",
    "    <td>39</td>\n",
    "    <td>0</td>\n",
    "    <td>39%</td>  \n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>1.000</td>\n",
    "    <td>100</td>\n",
    "    <td>403</td>\n",
    "    <td>0</td>\n",
    "    <td>40.3%</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10.000</td>\n",
    "    <td>1000</td>\n",
    "    <td>3.862</td>\n",
    "    <td>0</td>\n",
    "    <td>38.62%</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100.000</td>\n",
    "    <td>10.000</td>\n",
    "    <td>38.616</td>\n",
    "    <td>0</td>\n",
    "    <td>38.61%</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 2 - Entrenamiento del aprendiz ante el jugador aleatorio partiendo siempe desde los mismos pesos iniciales.</caption>\n",
    "</table>\n",
    "\n",
    "Aquí se puede visualizar que la cantidad de partidas ganadas no tiene grandes variaciones a medida que se aumenta la cantidad de partidas jugadas. Notar que la frecuencia de ajuste de los pesos se mantiene proporcional en todos los casos.\n",
    "\n",
    "En conclusión, a partir de los resultados obtenidos puede detectarse que no hay una mejora a través de la experiencia, es decir que una mayor cantidad de partidas jugadas no refleja una mayor cantidad de partidas ganadas (proporcionalmente). Por lo tanto hay errores inherentes al modelo, o no se cumple alguna hipótesis (puntos que se desarrollan en la sección 4).\n",
    "\n",
    "\n",
    "\n",
    "### 3.2 Fase de entrenamiento vs. la versión previa del aprendiz actual\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>  \n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>1</td>\n",
    "    <td>47</td>\n",
    "    <td>27</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>2</td>\n",
    "    <td>32</td>\n",
    "    <td>34</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>10</td>\n",
    "    <td>37</td>\n",
    "    <td>25</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>25</td>\n",
    "    <td>28</td>\n",
    "    <td>37</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 3 - Entrenamiento del aprendiz ante la versión previa partiendo desde los pesos iniciales obtenidos en el mejor resultado del entrenamiento anterior, variando la frecuencia de ajuste para una cantidad total de partidos fija.</caption>\n",
    "</table>\n",
    "\n",
    "En este caso, los mejores resultados se obtienen cuando los jugadores ajustan sus pesos al final de cada partida. En comparación con el mismo experimento realizado con el jugador aleatorio, la proporción de la frecuencia de ajuste es la misma. La diferencia está en la cantidad total de partidas jugadas. Para este caso se redujo el total de partidas ya que para una cantidad mayor a 100 los jugadores se estancan.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Frecuencia de ajuste</th>\n",
    "    <th>Partidos ganados</th>\n",
    "    <th>Partidos perdidos</th>\n",
    "    <th>Porcentaje de partidos ganados</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>1</td>\n",
    "    <td>4</td>\n",
    "    <td>3</td>\n",
    "    <td>40%</td>  \n",
    "  </tr>    \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>10</td>\n",
    "    <td>37</td>\n",
    "    <td>25</td>\n",
    "    <td>37%</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1.000</td>\n",
    "    <td>100</td>\n",
    "    <td>35</td>\n",
    "    <td>32</td>\n",
    "    <td>-</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10.000</td>\n",
    "    <td>1000</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100.000</td>\n",
    "    <td>10.000</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "  </tr>   \n",
    "    <caption>Tabla 4 - Entrenamiento del aprendiz ante la versión partiendo desde los pesos iniciales obtenidos en el mejor resultado del entrenamiento anterior.</caption>\n",
    "</table>\n",
    "\n",
    "HABLAR DE QUE SE EMPIEZA A TRANCAR LUEGO DE LOS 100 PARTIDOS. \n",
    "AGREGAR QUE SE PROBÓ CON OTROS PESOS INICIALES Y QUE EL RESULTADO MEJORA UN POCO PERO DESPUÉS DE 500 PARTIDOS SE VUELVE A TRANCAR. EXPLICAR POR QUE PASA ESTO (AJUSTA LOS PESOS BIEN AL PRINCIPIO PERO LUEGO DESAPRENDE).\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "       <td><img src=\"grafica.png\" alt=\"Drawing\" style=\"width: 800px;\"/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<caption>Gráfica 1: Evolución de los coeficientes de ajuste durante 530 partidos ajustando cada 10 partidos.</caption>\n",
    "\n",
    "### 3.3 Competencia entre los jugadores obtenidos durante las fases de entrenamiento\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Total de partidos jugados</th>\n",
    "    <th>Ganados por jugador entrenado vs. aleatorio</th>\n",
    "    <th>Ganados por jugador entrenado vs. versión previa</th>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>34</td>\n",
    "    <td>38</td> \n",
    "  </tr>    \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>100</td>\n",
    "    <td>33</td>\n",
    "    <td>38</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>35</td>\n",
    "    <td>31</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>33</td>\n",
    "    <td>33</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>33</td>\n",
    "    <td>32</td> \n",
    "  </tr>  \n",
    "    <caption>Tabla 5 - Resultados de la competencia entre los jugadores obtenidos con cada entrenamiento .</caption>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Culminadas las etapas del desarrollo del modelo y experimentación, puede concluirse que no se logró el objetivo de implementar un aprendiz 'competente', dado que no pudo canalizarse el aprendizaje a través de la experiencia.\n",
    "\n",
    "En el desarrollo del modelo, las elecciones con respecto al tablero tienen las siguientes limitantes:\n",
    "\n",
    "Durante la fase de entrenamiento frente al jugador aleatorio, los resultados en general son buenos, dado que en todos los casos de prueba el jugador logra el cometido de incrementar la cantidad de partidas ganadas a raíz de su experiencia.\n",
    "\n",
    "Los resultados obtenidos frente a la versión previa no son los esperados. Aquí se ve que el aprendizaje se frena considerablemente. Esto se debe a limitaciones asociadas al modelo propuesto e hipótesis que no se cumplen:\n",
    "* Dividir el tablero en segmentos de cercanía no fue provechoso, ya que se incurre en situaciones en las que al no cambiar de conjunto no hay retribución al avance, por lo que la ponderación de adelantar o atrasar una ficha (dentro del mismo rango) es igual.\n",
    "* La tupla elegida para representar el tablero contiene información relativa al jugador contrario, pero no se toman acciones que limiten su juego como por ejemplo el hecho de bloquearlo. (Durante el inicio de la etapa de la experimentación, se realizó una prueba de concepto donde solo se almacenó información relativa al jugador uno, pero esta no arrojó resultados alentadores.)\n",
    "* El aprendizaje inicial comienza su entrenamiento frente a un jugador aleatorio, por lo que la hipótesis de que en todo momento realizará el mejor movimiento posible no es válida, lo que puede llevar a condicionar la forma de jugar del jugador aprendiz.\n",
    "\n",
    "Sin embargo, futuras mejoras pueden guiar hacia mejores resultados:\n",
    "* Computar n jugadas siguientes de la instancia actual, de manera de evaluar un mayor conjunto de posibilidades (propias y del rival) asumiendo el costo computacional que conlleva.\n",
    "* Cambiar las regiones de distancia por la distancia propiamente dicha.\n",
    "* Considerar la posibilidad de bloquear las fichas del oponente.\n",
    "* Favorecer la estrategia de ataque utilizando saltos de largo mayor que 1.\n",
    "* Cambiar el contrincante puramente aleatorio, por uno con un criterio estático de decisión, que genere mejores datos de entrada, es decir que compita frente a una estrategia (macro) como puede ser: intentar avanzar siempre, intentar generar bloqueos, otras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apéndice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo fue codificado en el lenguaje Python (versión 3.7.2). Para ejecutarlo, basta con escribir la palabra python3 seguido de los siguientes parámetros:\n",
    "\n",
    "* cantidad_partidos: representa la cantidad total de partidos que el jugador aprendiz enfrentará a su oponente.\n",
    "* frecuencia_ajuste: representa la frecuencia con la que el jugador aprendiz ajustará sus pesos, es decir, la cantidad de partidos entre un ajuste y el siguiente.\n",
    "* versión_oponente: representa la versión del oponente contra la que jugará el jugador aprendiz. Para jugar contra el jugador aleatorio se debe ingresar 0, mientras que para jugar contra su versión anterior se debe ingresar 1.\n",
    "\n",
    "A continuación, se visualiza la sentencia completa y un ejemplo:\n",
    "\n",
    "$ python3  cantidad_partidos  frecuencia_ajuste  versión_oponente\n",
    "\n",
    "$ python3  100  10  1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
